{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333368e3-bb42-466c-8823-c45ed71f970f",
   "metadata": {},
   "source": [
    "# Prospecção de Dados (Data Mining) DI/FCUL - HA1\n",
    "\n",
    "## First Home Assignement (MC/DI/FCUL - 2024)\n",
    "\n",
    "### Fill in the section below\n",
    "\n",
    "### GROUP:`13`\n",
    "\n",
    "* Miguel Landum, 35019 - Hours worked on the project\n",
    "* Niklas Schmitz, 62689 - Hours worked on the project\n",
    "* Pol Parra, 62692 - Hours worked on the project\n",
    "* Til Dietrich, 62928 - Hours worked on the project\n",
    "\n",
    "\n",
    "The purpose of this Home Assignment is\n",
    "* Read a Data file with a Set of Texts\n",
    "* Compute similarities between texts\n",
    "* Perform simple classification of texts using a Naive Bayes classifier\n",
    "\n",
    "**NOTE 1: Students are not allowed to add more cells to the notebook**\n",
    "\n",
    "**NOTE 2: The notebook must be submited fully executed**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a40f24-0da5-4b96-90f3-84259cbd1bc5",
   "metadata": {},
   "source": [
    "## 1. Read the Dataset\n",
    "\n",
    "The dataset is the file `Sentences_75Agree.txt` from the [Financial Sentiment Analysis database on Gugging Face](https://huggingface.co/datasets/financial_phrasebank)\n",
    "\n",
    "* Read the dataset and separate them by unique documents (one document per line)\n",
    "* The last word of each document is the class and it **must be removed from the document** but kept separate for use in the classification tasks below\n",
    "    * classes can be `.@positive`, `.@negative`, `.@neutral`\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa918e91-c325-4c1d-8e8d-93d411035a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3453\n",
      "3453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .',\n",
       "  'With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .',\n",
       "  \"For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .\",\n",
       "  'In the third quarter of 2010 , net sales increased by 5.2 % to EUR 205.5 mn , and operating profit by 34.9 % to EUR 23.5 mn .',\n",
       "  'Operating profit rose to EUR 13.1 mn from EUR 8.7 mn in the corresponding period in 2007 representing 7.7 % of net sales .'],\n",
       " ['@neutral', '@positive', '@positive', '@positive', '@positive'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize documents and class lists\n",
    "documents = []\n",
    "classes = []\n",
    "\n",
    "# Open the file line by line as that should be more efficient than reading the whole file into memory with readlines() \n",
    "# and we have to use rfind for each line anyways\n",
    "with open('Sentences_75Agree.txt', 'r', encoding='ISO-8859-1') as file:\n",
    "    # Read line by line\n",
    "    for line in file:\n",
    "        # Find the class index\n",
    "        class_index = line.rfind('@')\n",
    "\n",
    "        # Split classes and document and append to respective lists\n",
    "        classes.append(line[class_index:].strip())\n",
    "        documents.append(line[:class_index].strip())\n",
    "\n",
    "print(len(documents))\n",
    "print(len(classes))\n",
    "documents[:5], classes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853614f3-1e1b-4481-9784-e29dd0b453cb",
   "metadata": {},
   "source": [
    "## 2. Compute similarities between texts\n",
    "\n",
    "* Compute the TF.IDF of all words in texts\n",
    "* compute the average similarity beween texts\n",
    "* Plot the document similarity distribution (suggestion use [boxplots](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html) or [histograms](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html) or  [histograms with density](https://matplotlib.org/stable/gallery/statistics/histogram_features.html))\n",
    "* Comment your results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead806d9-8073-4fc0-9668-68ad0b89077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add supporting functions here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80328c-ffba-4bb6-8ce3-03726ee82348",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add processing code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a87b8-4102-43ff-ac7c-e748df7bcd1f",
   "metadata": {},
   "source": [
    "### Your short analysis here\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8043c37-3a4d-4c4d-ab3e-2fae63af06fa",
   "metadata": {},
   "source": [
    "## 3. Make a Naive Bayes Classifier \n",
    "\n",
    "* Split dataset randomly into training and testing (20% for testing)\n",
    "* Train a Naive Bayes Model and do some sensitivity analyis on the hyperparameters \n",
    "* Evaluate your results with the testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdedab1a-54d8-49a3-8c08-4815bfc7d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add supporting functions here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72095268-f6c8-4156-98ce-662952ba22fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add processing code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547f4a00-01db-4c2c-a7b7-0a0f7ab0d333",
   "metadata": {},
   "source": [
    "## 4. Discuss your findings [to fill on your own]\n",
    "\n",
    "* Comment your results above\n",
    "* Discuss how could they be used in a Big Data environment\n",
    "\n",
    "\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

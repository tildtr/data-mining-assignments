{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predicted rating matrix. This will be use to perform predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Code to calculate the predicted rating matrix in human-readable format\n",
    "def compute_predicted_rating_matrix(P, Q, T, D, item_biases, user_biases, global_bias, user_features):\n",
    "    # Compute interaction terms\n",
    "    t_u = user_features @ T\n",
    "    d_u = user_features @ D\n",
    "    \n",
    "    # Compute predicted ratings matrix\n",
    "    predicted_ratings = np.dot(P + t_u, Q) + item_biases + user_biases[:, np.newaxis] + global_bias + d_u[:, np.newaxis]\n",
    "    \n",
    "    return predicted_ratings\n",
    "\n",
    "# Example usage:\n",
    "# Assuming P, Q, T, D, item_biases, user_biases, global_bias, and user_features are already trained and available\n",
    "predicted_rating_matrix = compute_predicted_rating_matrix(P, Q, T, D, item_biases, user_biases, global_bias, user_features)\n",
    "\n",
    "# Convert the matrix to a DataFrame for better visualization\n",
    "molecules_indices = range(user_biases.shape[0])\n",
    "proteins_indices = range(144) \n",
    "predicted_rating_df = pd.DataFrame(predicted_rating_matrix, index=molecules_indices, columns=proteins_indices)\n",
    "\n",
    "# Print the DataFrame\n",
    "display(predicted_rating_df)\n",
    "# TODO use dataframe to lookup pairs of the test.csv => first need to add column and row identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two groups of molecules we want to predict the activity for a specific protein: Molecules that were already present on the training data; molecules that were never seen before in the training data, therefore are not yet in the \"system\" (new users)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the acitivity for a protein of a molecule that is already in the \"system\" is easy. We just need to make a \"lookup\" in our predicted rating matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create interaction matrix\n",
    "def create_interaction_matrix(df, molecule_col, protein_col, activity_col):\n",
    "    interactions = df.pivot_table(index=molecule_col, columns=protein_col, values=activity_col, aggfunc='mean')\n",
    "    interactions = interactions.fillna(0)\n",
    "    return interactions\n",
    "\n",
    "\n",
    "# Compute predicted rating matrix\n",
    "predicted_rating_matrix = compute_predicted_rating_matrix(P, Q, T, D, item_biases, user_biases, global_bias, molecule_features)\n",
    "\n",
    "# Create the interaction matrix from your dataset\n",
    "interactions = create_interaction_matrix(df_activity, 'ChEMBL_IDs', 'Uniprot_IDs', 'Activity')\n",
    "\n",
    "# Get the indices (molecule IDs) and columns (protein IDs) from the interaction matrix\n",
    "molecule_ids = interactions.index\n",
    "protein_ids = interactions.columns\n",
    "\n",
    "# Create the DataFrame for the predicted ratings with the same indices and columns\n",
    "predicted_rating_df = pd.DataFrame(predicted_rating_matrix, index=molecule_ids, columns=protein_ids)\n",
    "\n",
    "# Alternatively, display the DataFrame in a Jupyter Notebook\n",
    "display(predicted_rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_rating(uniprot_id, chembl_id):\n",
    "    if chembl_id in predicted_rating_df.index and uniprot_id in predicted_rating_df.columns:\n",
    "        return predicted_rating_df.at[chembl_id, uniprot_id]\n",
    "    else:\n",
    "        return None  # or some default value like 0\n",
    "\n",
    "# Update the 'Activity' column in df_activity_validation\n",
    "df_activity_validation['Activity'] = df_activity_validation.apply(\n",
    "    lambda row: get_predicted_rating(row['Uniprot_IDs'], row['ChEMBL_IDs']), axis=1\n",
    ")\n",
    "\n",
    "# Print the updated df_activity_validation\n",
    "df_activity_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After predicting these activities we round the values to a whole integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activity_validation['Activity'] = df_activity_validation['Activity'].apply(lambda x: np.nan if pd.isna(x) else max(0, round(x)))\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df_activity_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are saving the rows that are empty in a csv. And in the next step read it in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty_activity  = pd.read_csv('df_empty_activity.csv')\n",
    "\n",
    "activity_train = pd.read_csv('activity_train.csv', header=None)\n",
    "# Define your column headers\n",
    "column_headers = ['Uniprot_IDs', 'ChEMBL_IDs', 'Activity']  \n",
    "# Read the CSV file with custom headers\n",
    "activity_train = pd.read_csv('activity_train.csv', names=column_headers)\n",
    "\n",
    "activity_test_blanked = pd.read_csv('activity_test_blanked.csv', header=None)\n",
    "# Define your column headers\n",
    "column_headers = ['Uniprot_IDs', 'ChEMBL_IDs', 'Activity']  \n",
    "# Read the CSV file with custom headers\n",
    "activity_test_blanked = pd.read_csv('activity_test_blanked.csv', names=column_headers)\n",
    "\n",
    "mol_bits = pd.read_pickle('mol_bits.pkl')\n",
    "\n",
    "def create_sparse_matrix(data):\n",
    "    ChEMBL_IDs = list(data.keys())\n",
    "    structural_features = list(data.values())\n",
    "\n",
    "    # Find the number of unique features\n",
    "    num_features = max(max(indices) for indices in structural_features) + 1\n",
    "\n",
    "    # Prepare data for csr_matrix\n",
    "    matrix_data = []\n",
    "    rows = []\n",
    "    cols = []\n",
    "\n",
    "    for row, indices in enumerate(structural_features):\n",
    "        rows.extend([row] * len(indices))\n",
    "        cols.extend(indices)\n",
    "        matrix_data.extend([1] * len(indices))\n",
    "\n",
    "    # Create the sparse matrix\n",
    "    sparse_matrix = csr_matrix((matrix_data, (rows, cols)), shape=(len(ChEMBL_IDs), num_features))\n",
    "    \n",
    "    return sparse_matrix, ChEMBL_IDs\n",
    "\n",
    "sparse_matrix, ChEMBL_IDs = create_sparse_matrix(mol_bits)\n",
    "dense_matrix_full = sparse_matrix.toarray()\n",
    "dense_matrix_full\n",
    "\n",
    "df_sparse_matrix = pd.DataFrame(dense_matrix_full, index=ChEMBL_IDs)\n",
    "\n",
    "def find_most_similar_molecules_above_threshold(df_empty_activity, df_sparse_matrix, threshold=0.8):\n",
    "    results = []\n",
    "    for index, row in df_empty_activity.iterrows():\n",
    "        chemble_id = row['ChEMBL_IDs']\n",
    "        similar_molecules = []\n",
    "        \n",
    "        # Check if ChEMBL_ID exists in df_sparse_matrix\n",
    "        if chemble_id not in df_sparse_matrix.index:\n",
    "            similar_molecules.append({\n",
    "                \"Most Similar Molecule\": \"NA\",\n",
    "                \"Jaccard Similarity\": 0\n",
    "            })\n",
    "        else:\n",
    "            molecule_vector = df_sparse_matrix.loc[chemble_id]\n",
    "            for other_chemble_id, other_vector in df_sparse_matrix.iterrows():\n",
    "                if other_chemble_id == chemble_id:\n",
    "                    continue  # Skip comparing the molecule to itself\n",
    "                intersection = (molecule_vector & other_vector).sum()\n",
    "                union = (molecule_vector | other_vector).sum()\n",
    "                jaccard_score = intersection / union if union > 0 else 0\n",
    "                if jaccard_score >= threshold:\n",
    "                    similar_molecules.append({\n",
    "                        \"Most Similar Molecule\": other_chemble_id,\n",
    "                        \"Jaccard Similarity\": jaccard_score\n",
    "                    })\n",
    "        \n",
    "        results.append({\n",
    "            \"Original Molecule\": chemble_id,\n",
    "            \"Similar Molecules Above Threshold\": similar_molecules\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "result_df = find_most_similar_molecules_above_threshold(df_empty_activity, df_sparse_matrix, threshold=0.6)\n",
    "\n",
    "# Convert the 'Similar Molecules Above Threshold' column to a structured string\n",
    "def format_similar_molecules(similar_molecules):\n",
    "    if isinstance(similar_molecules, list) and similar_molecules:\n",
    "        return \"; \".join([f\"{m['Most Similar Molecule']}:{m['Jaccard Similarity']}\" for m in similar_molecules])\n",
    "    return \"NA\"\n",
    "\n",
    "result_df['Similar Molecules Above Threshold'] = result_df['Similar Molecules Above Threshold'].apply(format_similar_molecules)\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv('most_similar_molecules.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the \"new users\" is harder. Our solution to that problem was to just calculate the jaccard similarity for all other molecules of these remaining molecules as they are not that many (1250 molecules in total). We can use the pickle file which includes fingerprints of the molecules, allowing us to perform a simlarity calculation. After running that code, we save it in a csv for easier reuse. This csv includes all the molecules that haven't been seen before, with their most similar molecules based on the jaccard similarity using a threshold for 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read back the CSV and parse the structured string\n",
    "def parse_similar_molecules(formatted_str):\n",
    "    if pd.isna(formatted_str) or formatted_str == \"NA\":\n",
    "        return []\n",
    "    return [{\"Most Similar Molecule\": m.split(\":\")[0], \"Jaccard Similarity\": float(m.split(\":\")[1])} for m in formatted_str.split(\"; \")]\n",
    "\n",
    "# Example of reading back the CSV\n",
    "def read_results_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Similar Molecules Above Threshold'] = df['Similar Molecules Above Threshold'].apply(parse_similar_molecules)\n",
    "    return df\n",
    "\n",
    "# Read the CSV\n",
    "similar_molecules_df = read_results_from_csv('most_similar_molecules.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_molecules_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we can use the similar molecules for the \"new\" molecules and take the average of the similar molecules for the protein that should be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the value for a given molecule and protein using similar molecules\n",
    "def predict_value(molecule, protein, similar_molecules_df, predicted_rating_df):\n",
    "    similar_molecules_entry = similar_molecules_df[similar_molecules_df['Original Molecule'] == molecule]\n",
    "    if similar_molecules_entry.empty:\n",
    "        return None  # Return None if no similar molecules are found\n",
    "\n",
    "    similar_molecules = similar_molecules_entry.iloc[0]['Similar Molecules Above Threshold']\n",
    "    \n",
    "    if not similar_molecules:\n",
    "        return None  # Return None if the similar molecules list is empty\n",
    "\n",
    "    # Extract the values for the specific protein column for all similar molecules\n",
    "    values = []\n",
    "    for similar in similar_molecules:\n",
    "        similar_molecule = similar['Most Similar Molecule']\n",
    "        if similar_molecule in predicted_rating_df.index and protein in predicted_rating_df.columns:\n",
    "            value = predicted_rating_df.loc[similar_molecule, protein]\n",
    "            values.append(value)\n",
    "\n",
    "    if not values:\n",
    "        return None  # Return None if no values are found\n",
    "\n",
    "    # Compute the average of the values and round it to the nearest integer\n",
    "    predicted_value = round(np.mean(values))\n",
    "    return predicted_value\n",
    "\n",
    "# Identify rows in the validation data that have missing activity values and are in the similar molecules DataFrame\n",
    "missing_activity_mask = df_activity_validation['Activity'].isna()\n",
    "original_molecules = similar_molecules_df['Original Molecule'].unique()\n",
    "mask = missing_activity_mask & df_activity_validation['ChEMBL_IDs'].isin(original_molecules)\n",
    "\n",
    "# Filter these rows\n",
    "missing_activity_rows = df_activity_validation[mask]\n",
    "\n",
    "# Update missing activity values using similar molecules\n",
    "for index, row in missing_activity_rows.iterrows():\n",
    "    molecule = row['ChEMBL_IDs']\n",
    "    if molecule in original_molecules:  # Check if molecule is in the original molecules\n",
    "        protein = row['Uniprot_IDs']\n",
    "        predicted_activity = predict_value(molecule, protein, similar_molecules_df, predicted_rating_df)\n",
    "        if predicted_activity is not None:\n",
    "            df_activity_validation.at[index, 'Activity'] = predicted_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activity_validation[df_activity_validation[\"Activity\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_activity_validation.to_csv('updated_activity_validation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
